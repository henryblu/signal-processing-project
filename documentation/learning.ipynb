{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66150,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(audio_data\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     12\u001b[0m \u001b[39m# decrease the audio data to one channel\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m audio_data \u001b[39m=\u001b[39m audio_data[:, \u001b[39m0\u001b[39;49m]\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(audio_data\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "try:\n",
    "    sample_rate, audio_data = wav.read(r\"C:\\Users\\henry\\OneDrive - University of Helsinki\\Documents\\University files\\Comp sci\\year 2\\data structures and algoithms project course\\signal-processing-project\\src\\Data\\StarWars3.wav\")\n",
    "except FileNotFoundError as exc:\n",
    "    raise FileNotFoundError(\"input file not found\") from exc\n",
    "audio_data = np.array(audio_data, dtype=float)\n",
    "# get the number of channels\n",
    "print(audio_data.shape)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def run(self):\n",
    "        \"\"\"this function is used to call the appropreate transform\n",
    "\n",
    "        Args:\n",
    "            rft (bool): if true the regular fourier transform will be used\n",
    "            fft (bool): if true the fast fourier transform will be used\n",
    "            sample_rate (int): the sample rate of the audio data\n",
    "            composite_signal (np.array): the audio data\n",
    "\n",
    "        Returns:\n",
    "            np.array: the fourier transform of the audio data\n",
    "            np.array: the noise reduced fourier transform\n",
    "            np.array: the inverse fourier transform of the noise reduced fourier transform\n",
    "        \"\"\"\n",
    "\n",
    "        if self.rft:\n",
    "            fourier_transform = self.regular_fourier_transform(self.og_audio_data)\n",
    "            noise_reduced_fourier_transform = noise_reduction(fourier_transform, 15)\n",
    "            inverse = self.inverse_regular_fourier_transform(\n",
    "                noise_reduced_fourier_transform\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            if not self.fft and self.verbose:\n",
    "                print(\"no fourier transform selected\")\n",
    "                print(\"defaulting to fast fourier transform\")\n",
    "                print()\n",
    "            if np.log2(self.length) % 1 != 0:\n",
    "                if self.verbose:\n",
    "                    print(\"the length of the audio data is not a power of 2\")\n",
    "                    print(\"using bluestein's fft\")\n",
    "                    print()\n",
    "                    fourier_transform = self.bluestein_fft(self.og_audio_data)\n",
    "                else:\n",
    "                    fourier_transform = self.fast_fourier_transform(self.og_audio_data)\n",
    "                noise_reduced_fourier_transform = noise_reduction(fourier_transform, 15)\n",
    "                inverse = self.inverse_fast_fourier_transform(\n",
    "                    noise_reduced_fourier_transform\n",
    "                )\n",
    "\n",
    "        fourier_transform = np.abs(fourier_transform[: self.length])\n",
    "        noise_reduced_fourier_transform = np.abs(\n",
    "            noise_reduced_fourier_transform[: self.length]\n",
    "        )\n",
    "        inverse = np.real(inverse[: self.length])\n",
    "\n",
    "        return fourier_transform, noise_reduced_fourier_transform, inverse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
